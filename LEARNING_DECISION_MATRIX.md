# Learning Approaches: Comprehensive Decision Matrix

## Quick Reference for All 10 Approaches

### Approach Comparison at a Glance

```
VIABILITY TIER 1: IMPLEMENT FIRST (Week 1-8)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. CHANGE POINT DETECTION (PELT)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Feasibility: âœ“âœ“âœ“ (Trivial)                    â”‚ Week: 1-2        â”‚
   â”‚ Complexity:  âœ“ (Low)                          â”‚ Effort: ~100 LOC â”‚
   â”‚ Interpretability: âœ“âœ“âœ“ (Excellent)             â”‚ Memory: 50MB     â”‚
   â”‚ "Eventâ†’Impact" Fit: âœ“âœ“âœ“ (Excellent)           â”‚ CPU: <1 sec      â”‚
   â”‚                                                                      â”‚
   â”‚ Why Start Here:                                                    â”‚
   â”‚ â€¢ Simplest algorithm (unsupervised)                               â”‚
   â”‚ â€¢ Runs daily on existing price data                               â”‚
   â”‚ â€¢ Shows exact dates when markets shift                            â”‚
   â”‚ â€¢ Natural foundation for all other methods                        â”‚
   â”‚ â€¢ Immediate operational value                                    â”‚
   â”‚                                                                      â”‚
   â”‚ Expected Output:                                                   â”‚
   â”‚ "VIX jumped 42% on 2024-01-15 (coincided with FOMC meeting)"    â”‚
   â”‚                                                                      â”‚
   â”‚ Next Action: Correlate detected breaks with event calendar       â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

2. CAUSAL INFERENCE (2SLS)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Feasibility: âœ“âœ“âœ“ (Feasible)                   â”‚ Week: 3-4        â”‚
   â”‚ Complexity:  âœ“âœ“ (Medium)                      â”‚ Effort: ~600 LOC â”‚
   â”‚ Interpretability: âœ“âœ“âœ“ (Excellent)             â”‚ Memory: <50MB    â”‚
   â”‚ "Eventâ†’Impact" Fit: âœ“âœ“âœ“ (Excellent)           â”‚ CPU: <1 sec      â”‚
   â”‚                                                                      â”‚
   â”‚ Why Essential:                                                    â”‚
   â”‚ â€¢ Most rigorous causality discovery                               â”‚
   â”‚ â€¢ Handles confounding (multiple events at once)                  â”‚
   â”‚ â€¢ Gives confidence intervals, not just point estimates           â”‚
   â”‚ â€¢ Interpretable: "War â†’ -2.5% returns (95% CI: -3.1% to -1.9%)" â”‚
   â”‚                                                                      â”‚
   â”‚ Expected Output:                                                   â”‚
   â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
   â”‚ â”‚ Event Type    Coefficient  95% CI        P-value â”‚              â”‚
   â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤              â”‚
   â”‚ â”‚ War           -0.025  [-0.035, -0.015]  0.001   â”‚              â”‚
   â”‚ â”‚ Sanctions     -0.012  [-0.018, -0.006]  0.002   â”‚              â”‚
   â”‚ â”‚ Trade Tension -0.003  [-0.008, +0.002]  0.350   â”‚              â”‚
   â”‚ â”‚ CB Rate Hike  +0.008  [+0.002, +0.014]  0.008   â”‚              â”‚
   â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
   â”‚                                                                      â”‚
   â”‚ Next Action: Monthly retraining as new events occur              â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

3. ANOMALY DETECTION (Isolation Forest)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Feasibility: âœ“âœ“âœ“ (Trivial)                    â”‚ Week: 2-3        â”‚
   â”‚ Complexity:  âœ“ (Low)                          â”‚ Effort: ~400 LOC â”‚
   â”‚ Interpretability: âœ“âœ“ (Good)                   â”‚ Memory: 50MB     â”‚
   â”‚ "Eventâ†’Impact" Fit: âœ“âœ“ (Good)                 â”‚ CPU: <1ms/point  â”‚
   â”‚                                                                      â”‚
   â”‚ Why Useful:                                                       â”‚
   â”‚ â€¢ Complements CPD (spikes vs. shifts)                            â”‚
   â”‚ â€¢ Unsupervised (no labels needed)                                â”‚
   â”‚ â€¢ Fast inference (real-time scoring)                             â”‚
   â”‚ â€¢ Foundation for opportunity detection                           â”‚
   â”‚                                                                      â”‚
   â”‚ Expected Output:                                                   â”‚
   â”‚ "S&P 500 return on 2024-02-15 was 3.2Ïƒ outlier (prob=0.002)"   â”‚
   â”‚                                                                      â”‚
   â”‚ Next Action: Cross-reference with event calendar + causal attr. â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

4. ACTIVE LEARNING (Uncertainty Sampling)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Feasibility: âœ“âœ“âœ“ (Trivial)                    â”‚ Week: 5-6        â”‚
   â”‚ Complexity:  âœ“ (Low)                          â”‚ Effort: ~400 LOC â”‚
   â”‚ Interpretability: âœ“âœ“âœ“ (Excellent)             â”‚ Memory: <10MB    â”‚
   â”‚ "Eventâ†’Impact" Fit: âœ“âœ“âœ“ (Excellent)           â”‚ CPU: <1 sec      â”‚
   â”‚                                                                      â”‚
   â”‚ Why Critical:                                                     â”‚
   â”‚ â€¢ Grows training data efficiently                                â”‚
   â”‚ â€¢ User provides ground truth (improves all models)               â”‚
   â”‚ â€¢ Simple UX: "These 10 events confuse usâ€”help us learn!"         â”‚
   â”‚ â€¢ Compounding: Each label improves future uncertainty ranking    â”‚
   â”‚                                                                      â”‚
   â”‚ Expected Output:                                                   â”‚
   â”‚ Monthly: 5-10 user labels + notes                                â”‚
   â”‚ Quarterly: Model confidence improves (0.73 â†’ 0.82)               â”‚
   â”‚                                                                      â”‚
   â”‚ Next Action: Build "Help Us Learn" tab in frontend              â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

5. BAYESIAN LINEAR REGRESSION (Spike-and-Slab)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Feasibility: âœ“âœ“âœ“ (Feasible)                   â”‚ Week: 6-8        â”‚
   â”‚ Complexity:  âœ“âœ“ (Medium)                      â”‚ Effort: ~700 LOC â”‚
   â”‚ Interpretability: âœ“âœ“âœ“ (Excellent)             â”‚ Memory: <50MB    â”‚
   â”‚ "Eventâ†’Impact" Fit: âœ“âœ“âœ“ (Excellent)           â”‚ CPU: ~30 sec mo. â”‚
   â”‚                                                                      â”‚
   â”‚ Why Essential:                                                    â”‚
   â”‚ â€¢ Automatic feature selection                                    â”‚
   â”‚ â€¢ Answers: "Which event types actually matter?"                  â”‚
   â”‚ â€¢ Probabilistic: P(War matters | data) = 0.94                   â”‚
   â”‚ â€¢ Complements causal inference (different angle)                â”‚
   â”‚                                                                      â”‚
   â”‚ Expected Output:                                                   â”‚
   â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
   â”‚ â”‚ Feature          P(â‰ 0)  Mean    95% CI     â”‚                    â”‚
   â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                    â”‚
   â”‚ â”‚ War              0.94   -2.5%   [-3.1%, -1.9%] â”‚                    â”‚
   â”‚ â”‚ Sanctions        0.87   -1.2%   [-1.8%, -0.6%] â”‚                    â”‚
   â”‚ â”‚ Political Tension 0.42  -0.05%  [-0.4%, +0.3%] â”‚                    â”‚
   â”‚ â”‚ Central Bank Hike 0.96   +0.8%   [+0.4%, +1.1%] â”‚                    â”‚
   â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
   â”‚                                                                      â”‚
   â”‚ Next Action: Identify insignificant features, refocus effort     â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

6. ANOMALY ATTRIBUTION (Causal + IF)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Feasibility: âœ“âœ“âœ“ (Feasible)                   â”‚ Week: 4-5        â”‚
   â”‚ Complexity:  âœ“âœ“ (Medium)                      â”‚ Effort: ~300 LOC â”‚
   â”‚ Interpretability: âœ“âœ“âœ“ (Excellent)             â”‚ Memory: <50MB    â”‚
   â”‚ "Eventâ†’Impact" Fit: âœ“âœ“âœ“ (Excellent)           â”‚ CPU: <1 sec      â”‚
   â”‚                                                                      â”‚
   â”‚ Why Powerful:                                                     â”‚
   â”‚ â€¢ Explains surprises: "Market moved unexpectedlyâ€”why?"          â”‚
   â”‚ â€¢ Uses causal inference to attribute blame/credit                â”‚
   â”‚ â€¢ Flags opportunities: "Unexplained anomalyâ€”investigate"         â”‚
   â”‚ â€¢ Weekly reporting builds user confidence                        â”‚
   â”‚                                                                      â”‚
   â”‚ Expected Output:                                                   â”‚
   â”‚ Weekly Report:                                                    â”‚
   â”‚ "VIX jumped 25% on 2024-01-15"                                  â”‚
   â”‚ "FOMC announcement explains 60% of jump (p=0.02)"               â”‚
   â”‚ "Remaining 40% unexplained (data error? latent factors?)"       â”‚
   â”‚                                                                      â”‚
   â”‚ Opportunity: "Anomaly > 3Ïƒ and unexplained. Investigate."       â”‚
   â”‚                                                                      â”‚
   â”‚ Next Action: Track quality of explanations (residuals)          â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


VIABILITY TIER 2: ADD IF PHASE 1 SUCCEEDS (Week 8-12)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

7. SYMBOLIC REGRESSION (Extend Existing)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Feasibility: âœ“âœ“âœ“ (Feasible)                   â”‚ Week: 6-8 (phase 2) â”‚
   â”‚ Complexity:  âœ“âœ“ (Medium)                      â”‚ Effort: ~200 LOC ext â”‚
   â”‚ Interpretability: âœ“âœ“âœ“ (Excellent)             â”‚ Memory: ~150MB       â”‚
   â”‚ "Eventâ†’Impact" Fit: âœ“âœ“âœ“ (Excellent)           â”‚ CPU: ~30 min/mo      â”‚
   â”‚                                                                      â”‚
   â”‚ Why Good Addition:                                                â”‚
   â”‚ â€¢ Discovered formulas are transparent & interpretable            â”‚
   â”‚ â€¢ Can discover non-linear relationships (formulas)               â”‚
   â”‚ â€¢ You already have genetic algorithm infrastructure              â”‚
   â”‚ â€¢ Complements linear causal models                               â”‚
   â”‚                                                                      â”‚
   â”‚ Expected Output:                                                   â”‚
   â”‚ Impact = -0.01Ã—Sentiment + 0.5Ã—SentimentÂ² - 0.0003Ã—DaysSince   â”‚
   â”‚ (Explains 65% of variance, RÂ² = 0.42)                           â”‚
   â”‚                                                                      â”‚
   â”‚ Next Action: Feed Bayesian feature importance as guidance       â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

8. HIDDEN MARKOV MODELS (Regime Detection Upgrade)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Feasibility: âœ“âœ“âœ“ (Feasible)                   â”‚ Week: 8-10 (phase 2)  â”‚
   â”‚ Complexity:  âœ“âœ“ (Medium)                      â”‚ Effort: ~600 LOC      â”‚
   â”‚ Interpretability: âœ“âœ“ (Good)                   â”‚ Memory: <50MB         â”‚
   â”‚ "Eventâ†’Impact" Fit: âœ“âœ“ (Good)                 â”‚ CPU: <1 sec           â”‚
   â”‚                                                                      â”‚
   â”‚ Why Nice to Have:                                                â”‚
   â”‚ â€¢ Probabilistic state transitions (more principled than current) â”‚
   â”‚ â€¢ States: Calm, Volatile, Crisis                                â”‚
   â”‚ â€¢ Detects state changes (events trigger transitions)            â”‚
   â”‚ â€¢ Integrates with regime-aware models (stratify by state)       â”‚
   â”‚                                                                      â”‚
   â”‚ Expected Output:                                                   â”‚
   â”‚ State Sequence: Calm (0.9) â†’ Chaotic (0.7) â†’ Stressed (0.6)   â”‚
   â”‚ P(Calmâ†’Chaotic | War) = 0.85                                   â”‚
   â”‚                                                                      â”‚
   â”‚ Next Action: Replace current regime detector gradually          â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

9. GAUSSIAN PROCESSES (Non-Linear Impact Functions)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Feasibility: âœ“âœ“âœ“ (Feasible) [up to ~500 events]                 â”‚ Week: 8-10 (phase 2)  â”‚
   â”‚ Complexity:  âœ“âœ“ (Medium)                      â”‚ Effort: ~500 LOC      â”‚
   â”‚ Interpretability: âœ“âœ“ (Good)                   â”‚ Memory: ~100MB        â”‚
   â”‚ "Eventâ†’Impact" Fit: âœ“âœ“ (Good)                 â”‚ CPU: ~20 sec/update   â”‚
   â”‚                                                                      â”‚
   â”‚ Why Optional:                                                     â”‚
   â”‚ â€¢ Non-parametric (no assumption on functional form)              â”‚
   â”‚ â€¢ Uncertainty bounds (wider where data sparse)                   â”‚
   â”‚ â€¢ Scales O(nÂ³) â€” don't exceed 500 events                        â”‚
   â”‚ â€¢ Better than Bayesian linear if relationships are curved       â”‚
   â”‚                                                                      â”‚
   â”‚ Expected Output:                                                   â”‚
   â”‚ At Sentiment=0.5:                                                â”‚
   â”‚   Predicted impact: -1.2% (95% CI: -2.1% to -0.3%)             â”‚
   â”‚   (High confidence; many similar historical events)              â”‚
   â”‚                                                                      â”‚
   â”‚ Next Action: Use when Bayesian linear saturates                â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


VIABILITY TIER 3: MAYBE LATER (Month 6+)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

10. KNOWLEDGE GRAPHS (Explicit Reasoning)
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Feasibility: âœ“âœ“ (Doable)                      â”‚ Month: 6+       â”‚
    â”‚ Complexity:  âœ“âœ“ (Medium)                      â”‚ Effort: ~800 LOCâ”‚
    â”‚ Interpretability: âœ“âœ“âœ“ (Excellent)             â”‚ Memory: ~50MB   â”‚
    â”‚ "Eventâ†’Impact" Fit: âœ“âœ“ (Good)                 â”‚ CPU: <1 sec     â”‚
    â”‚                                                                    â”‚
    â”‚ Why Consider:                                                  â”‚
    â”‚ â€¢ Transparent reasoning chains                                  â”‚
    â”‚ â€¢ Can encode domain knowledge explicitly                        â”‚
    â”‚ â€¢ Manual but interpretable                                      â”‚
    â”‚ â€¢ Integrates with causal inference (test hypotheses)           â”‚
    â”‚                                                                    â”‚
    â”‚ Expected Output:                                                 â”‚
    â”‚ [War in Ukraine] â†’affects_commodityâ†’ [Oil] â†’increases_priceâ†’   â”‚
    â”‚ [Energy stocks] â†’in_portfolioâ†’ [Your holdings]                 â”‚
    â”‚ â†’ Predicted impact: +2.3%                                       â”‚
    â”‚                                                                    â”‚
    â”‚ Next Action: Build incrementally, start with 10 entities      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


VIABILITY TIER 4: SKIP (Not viable for this domain)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ— Deep Learning (TensorFlow, PyTorch)
  âœ— No GPU on ARM hardware
  âœ— Slow inference, high memory
  âœ— Interpretability issues (black-box)
  âœ— Overkill for 50-100 training examples

âœ— Meta-Learning / Few-Shot Learning
  âœ— Requires expensive gradient-based optimization
  âœ— You don't have massive pre-training datasets
  âœ— Complex to implement and debug

âœ— Graph Neural Networks
  âœ— Memory-heavy on embedded hardware
  âœ— Slow training on ARM
  âœ— Opaque reasoning

âœ— Reinforcement Learning
  âœ— Portfolio management is already a solved optimization problem
  âœ— RL adds complexity without benefit
  âœ— Data-inefficient


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
IMPLEMENTATION PRIORITY RANKING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

WEEK 1-2:
  1. â­â­â­ Change Point Detection
     â””â”€ Immediate operational value, simplest algorithm

WEEK 3-4:
  2. â­â­â­ Causal Inference (2SLS)
     â””â”€ Most rigorous causality discovery

WEEK 4-5:
  3. â­â­â­ Anomaly Detection + Attribution
     â””â”€ Explains surprises, builds on CPD

WEEK 5-6:
  4. â­â­â­ Active Learning
     â””â”€ Grows training data, user engagement

WEEK 6-8:
  5. â­â­â­ Bayesian Linear Regression
     â””â”€ Feature selection, uncertainty quantification

MONTH 2 (IF TIME):
  6. â­â­ Symbolic Regression Extension
     â””â”€ Discovered formulas, non-linear relationships

MONTH 3 (IF VALIDATED):
  7. â­â­ Hidden Markov Models
     â””â”€ Regime detection upgrade

  8. â­ Gaussian Processes
     â””â”€ Non-parametric impact functions

  9. â­ Knowledge Graphs
     â””â”€ Explicit reasoning (nice-to-have)


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RESOURCE REQUIREMENTS SUMMARY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Phase 1 (8 weeks):
  Memory:    400-600MB (all 5 methods running)
  CPU:       ~3-5 min/month retraining
  Developer: 1 FTE (or 2 part-time)
  Data:      50-100 curated events

Phase 2 (4 weeks):
  Memory:    600-800MB
  CPU:       ~10-15 min/month retraining
  Developer: 0.5 FTE
  Data:      100-200 events (via active learning)

Deployment Target:
  Arduino Uno Q (2GB ARM64):
  âœ“ All Phase 1 methods fit easily
  âœ“ Phase 2 methods fit, slower retraining
  âœ“ Max sustainable: 200-300 training examples


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SUCCESS CRITERIA CHECKLIST
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

By Week 8:
  â˜ Can explain 50-70% of major market moves to events
  â˜ Event catalog: 50+ events with documented impacts
  â˜ Active learning: 20+ user labels collected
  â˜ Monthly retraining runs in < 5 minutes
  â˜ Models show confidence intervals (not point estimates)
  â˜ Causal effects significant at p < 0.10 level
  â˜ Anomaly attribution explains 60%+ of detected breaks

By Month 3 (Phase 2):
  â˜ Can explain 70-80% of market moves
  â˜ 5-7 independent models voting (ensemble)
  â˜ Opportunity detection flags 2-3 high-quality trades/month
  â˜ User confidence in system increasing (validation data)
  â˜ Feature importance rankings stable (not noisy)

By Month 6+:
  â˜ Models inform allocation decisions
  â˜ Event sensitivity integrated into risk dashboard
  â˜ Causal relationships documented & stable
  â˜ Live trading results validate predictions


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
DECISION FLOWCHART
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

START
  â”‚
  â”œâ”€ Do you have/can you curate 50+ historical events?
  â”‚  â”œâ”€ NO  â†’ Spend 2-3 weeks on event research first
  â”‚  â””â”€ YES â†’ Continue
  â”‚
  â”œâ”€ Can you spare 1 FTE Ã— 8 weeks?
  â”‚  â”œâ”€ NO  â†’ Reduce scope to Phase 1a (CPD + Causal only = 4 weeks)
  â”‚  â””â”€ YES â†’ Continue
  â”‚
  â”œâ”€ Can you label 5-10 uncertain events per month?
  â”‚  â”œâ”€ NO  â†’ Skip active learning, reduce model improvement rate
  â”‚  â””â”€ YES â†’ Continue (this is critical)
  â”‚
  â”œâ”€ Are you willing to accept models that are 70-80% accurate initially?
  â”‚  â”œâ”€ NO  â†’ Adjust expectations or add more domain expertise
  â”‚  â””â”€ YES â†’ Continue
  â”‚
  â”œâ”€ Do you want models to inform allocation or just inform thinking?
  â”‚  â”œâ”€ "Just inform" â†’ Simpler integration, lower risk
  â”‚  â””â”€ "Inform allocation" â†’ Need stricter confidence thresholds
  â”‚
  â””â”€ PROCEED with Phase 1 implementation
     Cost: 1 FTE Ã— 8 weeks + 50+ hours event curation
     Benefit: Statistically rigorous geopolitical impact learning


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

## Key Takeaways

### âœ“ What Will Succeed
1. **Change Point Detection**: Start here (Week 1-2)
2. **Causal Inference**: Foundation for understanding (Week 3-4)
3. **Bayesian Methods**: Answer "what matters?" (Week 6-8)
4. **Active Learning**: Grow data efficiently (Week 5-6)
5. **Symbolic Regression**: Discovered formulas (Phase 2)

### âœ— What Won't Work
- Deep learning (no GPU, slow on ARM)
- Meta-learning (expensive, you lack pre-training data)
- RL (over-engineered for this problem)
- GNNs (memory/CPU prohibitive)

### âš ï¸ Critical Unknowns
1. Event catalog: Do you have 50+ events?
2. Feedback loop: Can you label 5-10/month?
3. Latency: Can you afford 30+ min retraining?
4. Risk tolerance: How confident must models be?

### ğŸ¯ Expected Outcome
By Week 8: Models explain 50-70% of major market moves
By Week 12: Models explain 70-80% of market moves
By Month 6: Models inform allocation decisions

---

**Ready to build this? Start with Change Point Detection. Week 1.**
